= 301 Project 01 - Choosing a Model

== Project Objectives

In this project, we will learn how to select an appropriate machine learning model. Understanding specifics of how the models work may help in this process, but other aspects can be investigated for this. 

== Extra Reading and Resources

- https://the-examples-book.com/starter-guides/data-science/data-modeling/choosing-model/[DataMine Examples Book - Choosing a Model]

== Dataset
- `/anvil/projects/tdm/data/boston.csv`

== Questions


=== Question 1 (2 points)

One of the most important parts of picking a model is understanding your data. This determines if your model will be regression or classification based.
To explore this, we will use the boston dataset. Load it using the code below

[source,python]
----
import pandas as pd
 
my_df = pd.read_csv('/anvil/projects/tdm/data/boston.csv')
----

The first step of choosing data for a ML model is choosing what our output variable should be.
For this project, we will use the `MEDV` column as our output variable.

Once we know what the output variable is, we should seperate it from the input features

[source,python]
----
# Split the dataset into features and target variable
X = my_df.drop('MEDV', axis=1)   
y = my_df['MEDV']
----

In order to evaluate how well the machine learning model is performing, we will split our dataset into training and testing sets.
scikit-learn is a great python library for machine learning, and you will be using it all the time during these projects. It is recommended to read their documentation thoroughly.

[source,python]
----
from sklearn.model_selection import train_test_split
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
----

Print the first few rows of the training data input features. You may notice that each feature may have a drastically different range.
This can cause problems for some machine learning models. In order to fix this, it is standard to scale the features before training.
We can do this using the scikit-learn `StandardScaler`
[source,python]
----
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
# scale the training data
X_train_scaled = scaler.fit_transform(X_train)
# scale the testing data
X_test_scaled = scaler.transform(X_test)
----

You may notice that we used a different function for the training and testing data. There is a reason for it. 
Please read https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling[this guide on standardization]


Deliverables
.. Please explain why we used different functions for `X_train_scaled` and `X_test_scaled`.
.. What type of data is is the MEDV column. Would a regression or classification model be more appropriate?


=== Question 2 (2 points)

**Flexibility vs. Interpretability**

Flexible models are used for complex and unstructured datasets more effectively, but they are usually considered as "black boxes"; their outputs are not easily explainable.

Interpretable models' outputs are easily understood and provide insight into which features are responsible for the prediction.

Please read https://www.baeldung.com/cs/ml-flexible-and-inflexible-models[this article] to learn more about flexibility, inflexibility, and interpretability.  
 
.. Please describe the main difference between flexible and interpretable models in your own words.
.. Please read https://the-examples-book.com/starter-guides/data-science/data-modeling/choosing-model/flexibility-interpret[this Examples book page], and choose one model for each that are flexible or interpretable

 


=== Question 3 (2 points)


**Classification vs. Regression**

Classification is when we classify data into distinct groups such as eye color like blue or black, or animal types like dog or cat.

Classification model will put existing data into different groups.

A regression model will produce predicted future data as numeric values like income or age.

For example: Logistic regression is for binary classification. A binary classification problem is one where the output can only be one of two possible values, usually true or false, 0 or 1, etc.

In contrast, linear regression is for predicting a continuous target variable as numeric data, for example: predicting a house's price based on the house's features.


.. Describe the main difference between classification problems and regression problems in your own words.
.. Describe a situation where classification would be useful vs. regression and vice versa.
  


=== Question 4 (2 points)


**Prediction vs. Inference**

Predictive models focus on forecasting, like using historical house prices to predict future house prices.

Inferential models focus on understanding relationships, like understanding underlying factors that impact house prices.

Visit https://www.datascienceblog.net/post/commentary/inference-vs-prediction/[this link] to learn more on the comparison of prediction and inference.

 
.. Explain when you would use prediction versus inference in modeling and why, in your own words.



=== Question 5 (2 points)


**Supervised vs. Unsupervised Learning**

Supervised learning is when correct predictions are provided to the model; it allows the model to learn the mapping from inputs to the desired outputs, like using labeled data that has features and a labeled column to predict if an animal is a dog or a cat, and learning from the correct or incorrect predictions made.

Unsupervised learning does not provide model with correct predictions, instead it provides incentive for the model to grow unstructured in the right direction; it uncovers patterns or structures within the data.

Please read https://domino.ai/blog/supervised-vs-unsupervised-learning[this article], which provides more comparison of supervised and unsupervised learning.


**Parameterization vs. Non-Parameterization**

Parameterization involves assigning parameters (starting values) to develop a function.

Non-Parameterization uses the data itself to derive the function parameters instead of predefined parameters.

Please read https://www.geeksforgeeks.org/difference-between-parametric-and-non-parametric-methods/[this article] for an in-depth look at the concepts of parameterization and non-parameterization.

.. Use your own words to explain the difference between supervised and unsupervised learning with simple examples.
.. Use your own words to describe the difference between Parametric models and non-parametric models.


Project 01 Assignment Checklist
====
* Jupyter Lab notebook with your code, comments, and output for the assignment
    ** `firstname-lastname-project01.ipynb` 

* Submit files through Gradescope
====

[WARNING]
====
_Please_ make sure to double-check that your submission is complete and contains all of your code and output before submitting. If you have a spotty internet connection, it is recommended to download your submission after submitting it to ensure what you _think_ you submitted is what you _actually_ submitted.

In addition, please review our https://the-examples-book.com/projects/submissions[submission guidelines] before submitting your project.
====
